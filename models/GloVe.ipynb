{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GloVe.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yD295iy42cg1",
        "outputId": "6cacdea5-94cb-420c-f281-37fdbe9c1dfd"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import regex as re\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.preprocessing import sequence\n",
        "from tensorflow.python.keras.preprocessing import text\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM,Bidirectional, GlobalMaxPool1D,Dropout,Flatten\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MczVfr6I2o7-",
        "outputId": "c0192e8f-1bc5-48b8-9ccf-41edb7019826"
      },
      "source": [
        "data = pd.read_csv('final_texts.csv',index_col=0)\n",
        "data.reset_index(drop=True,inplace = True)\n",
        "\n",
        "for i,j in enumerate(data['labels']):\n",
        "  try:\n",
        "    j = int(j)\n",
        "  except ValueError as e:\n",
        "    print(f'error on {i} line')\n",
        "data.drop(labels=[2478],inplace= True)\n",
        "data['labels'].astype(int);\n",
        "data.dropna(inplace = True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "error on 2478 line\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqRK7SHV28zy"
      },
      "source": [
        "cleaned_text = []\n",
        "for text in data['texts']:\n",
        "  text = \" \".join(word for word in text.split() if not word.isdigit())\n",
        "  cleaned_text.append(text)\n",
        "data['cleaned_text'] = cleaned_text"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mxx66Xz3AIJ"
      },
      "source": [
        "vocab =  {}\n",
        "for text in data['cleaned_text']:\n",
        "  sen = text.split()\n",
        "  for word in sen:\n",
        "    try:\n",
        "      vocab[word] += 1\n",
        "    except KeyError:\n",
        "      vocab[word] = 1\n",
        "vocab = dict(sorted(vocab.items(), key=lambda item: item[1]))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ5K0hs53DjZ"
      },
      "source": [
        "rare_words = []\n",
        "for key,value in vocab.items():\n",
        "  if value<=10:\n",
        "    rare_words.append(key)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pvn8Y-oD3GcO"
      },
      "source": [
        "stopwords_en = set(stopwords.words('english'))\n",
        "cleaner_text = []\n",
        "for text in data['cleaned_text']:\n",
        "  text = \" \".join([word for word in text.split() if len(word)>2 and word not in stopwords_en and word not in rare_words])\n",
        "  cleaner_text.append(text)\n",
        "data['final_text'] = cleaner_text"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMzTqM5j3KII"
      },
      "source": [
        "vocab =  {}\n",
        "for text in data['final_text']:\n",
        "  sen = text.split()\n",
        "  for word in sen:\n",
        "    try:\n",
        "      vocab[word] += 1\n",
        "    except KeyError:\n",
        "      vocab[word] = 1\n",
        "vocab = dict(sorted(vocab.items(), key=lambda item: item[1]))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMZgFbC33QSQ"
      },
      "source": [
        "vocab_list = list(vocab.items())\n",
        "vocab_size = len(vocab)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DW1cvb0d3S3z"
      },
      "source": [
        "x = data['final_text'].values\n",
        "y = data['labels'].values\n",
        "X_train,X_test,y_train, y_test = train_test_split(x,y, test_size = 0.2, shuffle = True)\n",
        "y_train = y_train.astype(int)\n",
        "y_test = y_test.astype(int)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiCTig0y3j9u",
        "outputId": "26d7497e-bfb2-4be5-9fd5-e26dd94696d3"
      },
      "source": [
        "embeddings_index = dict()\n",
        "f = open('glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 1216 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3xl2Fz33WSb"
      },
      "source": [
        "from tensorflow.python.keras.preprocessing import sequence\n",
        "from tensorflow.python.keras.preprocessing import text\n",
        "tokenizer = text.Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "X_train = sequence.pad_sequences(X_train,maxlen=200)\n",
        "X_test = sequence.pad_sequences(X_test,maxlen=200)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjKPmTVn3Yvs"
      },
      "source": [
        "tokens = len(tokenizer.word_index) + 2\n",
        "embedding_matrix = np.zeros((tokens, 200))\n",
        "count = 0\n",
        "unknown = []\n",
        "for word, i in tokenizer.word_index.items():\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    try:\n",
        "      embedding_matrix[i] = embedding_vector\n",
        "    except ValueError:\n",
        "      unknown.append(word)\n",
        "      count += 1\n",
        "  else:\n",
        "    unknown.append(word)\n",
        "    count += 1"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIUo5bUs3b5o",
        "outputId": "05de3b61-424f-45f7-d2dd-6d1e6e8fee8e"
      },
      "source": [
        "print(1-(count/vocab_size))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2648725212464589\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7zckA9U3sKp",
        "outputId": "a2c327a7-1b05-4e20-bffe-7402cf7d95dc"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(tokens,200,weights = [embedding_matrix],input_length = embedding_matrix.shape[1]))\n",
        "model.add(LSTM(64))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(optimizer='adam',loss = 'binary_crossentropy',metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 200, 200)          282800    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                67840     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 350,705\n",
            "Trainable params: 350,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6S5NSD63xdz",
        "outputId": "81de2b8a-d4cc-4970-81a6-6b36a572c3d5"
      },
      "source": [
        "model.fit(X_train,y_train,epochs=30)\n",
        "loss,accuracy = model.evaluate(X_train,y_train)\n",
        "print(f'acc: {accuracy}')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "323/323 [==============================] - 4s 12ms/step - loss: 0.1025 - accuracy: 0.9500\n",
            "Epoch 2/30\n",
            "323/323 [==============================] - 4s 12ms/step - loss: 0.0986 - accuracy: 0.9491\n",
            "Epoch 3/30\n",
            "323/323 [==============================] - 4s 12ms/step - loss: 0.0965 - accuracy: 0.9514\n",
            "Epoch 4/30\n",
            "323/323 [==============================] - 4s 12ms/step - loss: 0.0951 - accuracy: 0.9522\n",
            "Epoch 5/30\n",
            "323/323 [==============================] - 4s 12ms/step - loss: 0.0940 - accuracy: 0.9514\n",
            "Epoch 6/30\n",
            "323/323 [==============================] - 4s 12ms/step - loss: 0.0933 - accuracy: 0.9521\n",
            "Epoch 7/30\n",
            "323/323 [==============================] - 4s 12ms/step - loss: 0.0928 - accuracy: 0.9520\n",
            "Epoch 8/30\n",
            "323/323 [==============================] - 4s 12ms/step - loss: 0.0916 - accuracy: 0.9515\n",
            "Epoch 9/30\n",
            "323/323 [==============================] - 4s 12ms/step - loss: 0.0908 - accuracy: 0.9527\n",
            "Epoch 10/30\n",
            "323/323 [==============================] - 4s 12ms/step - loss: 0.0902 - accuracy: 0.9527\n",
            "Epoch 11/30\n",
            "323/323 [==============================] - 4s 12ms/step - loss: 0.0967 - accuracy: 0.9501\n",
            "Epoch 12/30\n",
            "323/323 [==============================] - 4s 12ms/step - loss: 0.0928 - accuracy: 0.9522\n",
            "Epoch 13/30\n",
            "323/323 [==============================] - 4s 12ms/step - loss: 0.0893 - accuracy: 0.9535\n",
            "Epoch 14/30\n",
            "323/323 [==============================] - 4s 12ms/step - loss: 0.0882 - accuracy: 0.9539\n",
            "Epoch 15/30\n",
            "323/323 [==============================] - 4s 12ms/step - loss: 0.0886 - accuracy: 0.9522\n",
            "Epoch 16/30\n",
            "323/323 [==============================] - 4s 12ms/step - loss: 0.0877 - accuracy: 0.9532\n",
            "Epoch 17/30\n",
            "323/323 [==============================] - 4s 12ms/step - loss: 0.0874 - accuracy: 0.9543\n",
            "Epoch 18/30\n",
            "323/323 [==============================] - 4s 12ms/step - loss: 0.0875 - accuracy: 0.9533\n",
            "Epoch 19/30\n",
            "323/323 [==============================] - 4s 12ms/step - loss: 0.0872 - accuracy: 0.9541\n",
            "Epoch 20/30\n",
            "323/323 [==============================] - 4s 12ms/step - loss: 0.0872 - accuracy: 0.9519\n",
            "Epoch 21/30\n",
            "323/323 [==============================] - 4s 12ms/step - loss: 0.0866 - accuracy: 0.9547\n",
            "Epoch 22/30\n",
            "323/323 [==============================] - 4s 12ms/step - loss: 0.0869 - accuracy: 0.9539\n",
            "Epoch 23/30\n",
            "323/323 [==============================] - 4s 12ms/step - loss: 0.0862 - accuracy: 0.9534\n",
            "Epoch 24/30\n",
            "323/323 [==============================] - 4s 12ms/step - loss: 0.0857 - accuracy: 0.9526\n",
            "Epoch 25/30\n",
            "323/323 [==============================] - 4s 12ms/step - loss: 0.0858 - accuracy: 0.9534\n",
            "Epoch 26/30\n",
            "323/323 [==============================] - 4s 12ms/step - loss: 0.0854 - accuracy: 0.9542\n",
            "Epoch 27/30\n",
            "323/323 [==============================] - 4s 12ms/step - loss: 0.0856 - accuracy: 0.9536\n",
            "Epoch 28/30\n",
            "323/323 [==============================] - 4s 12ms/step - loss: 0.0860 - accuracy: 0.9536\n",
            "Epoch 29/30\n",
            "323/323 [==============================] - 4s 12ms/step - loss: 0.0900 - accuracy: 0.9521\n",
            "Epoch 30/30\n",
            "323/323 [==============================] - 4s 12ms/step - loss: 0.0871 - accuracy: 0.9539\n",
            "323/323 [==============================] - 2s 5ms/step - loss: 0.0805 - accuracy: 0.9574\n",
            "acc: 0.957430362701416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n4ypG0k3zuU"
      },
      "source": [
        "predictions = model.predict(X_test)\n",
        "predictions = np.round(predictions)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Umu3oD3B2XQ",
        "outputId": "57eae875-3f8e-4525-ac70-ab7f9e63090e"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "score = accuracy_score(y_test,predictions)\n",
        "cm = confusion_matrix(y_test,predictions)\n",
        "print(\"score: {} cm: {}\".format(score,cm))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score: 0.8077369439071567 cm: [[1100  284]\n",
            " [ 213  988]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ioDYHEMB57n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}